{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ISLR\n",
      "\n",
      "Loading required package: MASS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "require(ISLR)\n",
    "require(MASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Call:\n",
       "lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = Year < \n",
       "    2005)\n",
       "\n",
       "Prior probabilities of groups:\n",
       "    Down       Up \n",
       "0.491984 0.508016 \n",
       "\n",
       "Group means:\n",
       "            Lag1        Lag2\n",
       "Down  0.04279022  0.03389409\n",
       "Up   -0.03954635 -0.03132544\n",
       "\n",
       "Coefficients of linear discriminants:\n",
       "            LD1\n",
       "Lag1 -0.6420190\n",
       "Lag2 -0.5135293"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Response is direction, 2 predictors Lag1 and 2.\n",
    "# Data is coming from Stock Market\n",
    "# Subset is years less than 2005 because later on we'll make predictions\n",
    "lda.fit <- lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = Year < 2005)\n",
    "# Prior probabilities are proportions of ups and downs in the dataset.\n",
    "# (Roughly 50%) which says something about the market, it's pretty random, half\n",
    "# The time it goes up, half the time it goes down.\n",
    "# It summarizes the group means for the two groups.\n",
    "# Then it gives the LDA coefficients. Linear function for separating the two groups.\n",
    "lda.fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Two group histograms look very similar... No surprise, it's not easy to predict the stock market.\n",
    "plot(lda.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# See how well our rule predicts on the year 2005\n",
    "# First param is the dataset, Stock Market...\n",
    "# Second param is logical expressions that can\n",
    "# use the variables in that dataframe to define the subset.\n",
    "Smarket.2005 <- subset(Smarket, Year == 2005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in lda.pred[1:5, ]: incorrect number of dimensions\n",
     "output_type": "error",
     "traceback": [
      "Error in lda.pred[1:5, ]: incorrect number of dimensions\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Use that as the test data; call predict.\n",
    "lda.pred <- predict(lda.fit, Smarket.2005)\n",
    "# Print the first 5 of these.\n",
    "lda.pred[1:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'list'"
      ],
      "text/latex": [
       "'list'"
      ],
      "text/markdown": [
       "'list'"
      ],
      "text/plain": [
       "[1] \"list\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>class</th><th scope=col>posterior.Down</th><th scope=col>posterior.Up</th><th scope=col>LD1</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>999</th><td>Up</td><td>0.4901792</td><td>0.5098208</td><td> 0.08293096</td></tr>\n",
       "\t<tr><th scope=row>1000</th><td>Up</td><td>0.4792185</td><td>0.5207815</td><td> 0.59114102</td></tr>\n",
       "\t<tr><th scope=row>1001</th><td>Up</td><td>0.4668185</td><td>0.5331815</td><td> 1.16723063</td></tr>\n",
       "\t<tr><th scope=row>1002</th><td>Up</td><td>0.4740011</td><td>0.5259989</td><td> 0.83335022</td></tr>\n",
       "\t<tr><th scope=row>1003</th><td>Up</td><td>0.4927877</td><td>0.5072123</td><td>-0.03792892</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & class & posterior.Down & posterior.Up & LD1\\\\\n",
       "  & <fct> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t999 & Up & 0.4901792 & 0.5098208 &  0.08293096\\\\\n",
       "\t1000 & Up & 0.4792185 & 0.5207815 &  0.59114102\\\\\n",
       "\t1001 & Up & 0.4668185 & 0.5331815 &  1.16723063\\\\\n",
       "\t1002 & Up & 0.4740011 & 0.5259989 &  0.83335022\\\\\n",
       "\t1003 & Up & 0.4927877 & 0.5072123 & -0.03792892\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 4\n",
       "\n",
       "| <!--/--> | class &lt;fct&gt; | posterior.Down &lt;dbl&gt; | posterior.Up &lt;dbl&gt; | LD1 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 999 | Up | 0.4901792 | 0.5098208 |  0.08293096 |\n",
       "| 1000 | Up | 0.4792185 | 0.5207815 |  0.59114102 |\n",
       "| 1001 | Up | 0.4668185 | 0.5331815 |  1.16723063 |\n",
       "| 1002 | Up | 0.4740011 | 0.5259989 |  0.83335022 |\n",
       "| 1003 | Up | 0.4927877 | 0.5072123 | -0.03792892 |\n",
       "\n"
      ],
      "text/plain": [
       "     class posterior.Down posterior.Up LD1        \n",
       "999  Up    0.4901792      0.5098208     0.08293096\n",
       "1000 Up    0.4792185      0.5207815     0.59114102\n",
       "1001 Up    0.4668185      0.5331815     1.16723063\n",
       "1002 Up    0.4740011      0.5259989     0.83335022\n",
       "1003 Up    0.4927877      0.5072123    -0.03792892"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Oops, result is a list, let's cast to a Data Frame to look.\n",
    "class(lda.pred)\n",
    "data.frame(lda.pred)[1:5,] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      \n",
       "       Down  Up\n",
       "  Down   35  35\n",
       "  Up     76 106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Table of the class as the prediction vs the true value as the response.\n",
    "table(lda.pred$class, Smarket.2005$Direction)\n",
    "# We get a confusion matrix which tells us which downs were classified as down,\n",
    "# which downs were classified as up, and the diagonal elements which are the\n",
    "# correct classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.55952380952381"
      ],
      "text/latex": [
       "0.55952380952381"
      ],
      "text/markdown": [
       "0.55952380952381"
      ],
      "text/plain": [
       "[1] 0.5595238"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicted class is equal to the true class\n",
    "# Trues and falses can be coerced to be 1 or 0, so we can take the mean of that.\n",
    "mean(lda.pred$class == Smarket.2005$Direction)\n",
    "# Not huge, but in this kind of industry any little edge helps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
